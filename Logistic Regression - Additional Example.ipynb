{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Rhyme](https://rhyme.com/assets/img/logo-dark.png)\n",
    "\n",
    "# Deep Learning Fundamentals - Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data from UCI ML Repository. [Click here](https://archive.ics.uci.edu/ml/datasets/banknote+authentication) for bank note authentication dataset description or execute the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt  -o banknote.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import helpers.plt\n",
    "import helpers\n",
    "\n",
    "from logistic_regression import LogisticModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the downloaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('banknote.csv', names=['variance', 'skewness', 'curtosis', 'entropy', 'class'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features and labels as numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].values\n",
    "Y = df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle and normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_examples = X.shape[0]\n",
    "print('Found', total_examples, 'total examples.')\n",
    "\n",
    "# Shuffle dataset\n",
    "indices = np.random.randint(0, total_examples, total_examples)\n",
    "X = X[indices]\n",
    "Y = Y[indices]\n",
    "\n",
    "# Normalize data\n",
    "X = (X - np.mean(X, axis=0))/np.std(X, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:1000]\n",
    "Y_train = Y[:1000]\n",
    "X_test = X[1000:]\n",
    "Y_test = Y[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to generate random mini batch. It should confirm to how the train function in the logistic model works. Therefore, it should accept `(X, Y, batch_size)` in that order and return `(X_batch, Y_batch)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X, Y, batch_size):\n",
    "    num_total = X.shape[0]\n",
    "    X_batch = np.zeros((batch_size, 4))\n",
    "    Y_batch = np.zeros((batch_size, 1))\n",
    "    indices = np.random.randint(0, num_total, batch_size)\n",
    "    \n",
    "    for i, index in enumerate(indices):\n",
    "        X_batch[i] = X[index]\n",
    "        Y_batch[i] = Y[index]\n",
    "    \n",
    "    return X_batch, Y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a LogisticModel and evaluate the untrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticModel(num_features=4)\n",
    "model.summary()\n",
    "\n",
    "print('Initial values for W and b:')\n",
    "print('W =', list(np.squeeze(model.W)))\n",
    "print('b =', np.squeeze(model.b))\n",
    "\n",
    "X, Y = generate_batch(X_test, Y_test, 100)\n",
    "acc, loss = model.evaluate(X, Y)\n",
    "print('Untrained model accuracy:', 100*acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model and evaluate accuracy again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(\n",
    "    batch_size=100,\n",
    "    get_batch=generate_batch,\n",
    "    lr=10.0,\n",
    "    iterations=10,\n",
    "    X_train=X_train, Y_train=Y_train,\n",
    "    X_test=X_test, Y_test=Y_test\n",
    ")\n",
    "\n",
    "X, Y = generate_batch(X_test, Y_test, 100)\n",
    "acc, loss = model.evaluate(X, Y)\n",
    "print('Trained model accuracy:', 100*acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the validation accuracy and loss during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.plt.plot_metrics(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Learned values for W and b:')\n",
    "print('W =', list(np.squeeze(model.W)))\n",
    "print('b =', np.squeeze(model.b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
